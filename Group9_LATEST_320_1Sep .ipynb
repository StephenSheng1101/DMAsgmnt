{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Understanding"
      ],
      "metadata": {
        "id": "nYMo6Hyb27kC"
      },
      "id": "nYMo6Hyb27kC"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ab47e200-f833-4e8c-81f9-c63c5b3fc350",
      "metadata": {
        "id": "ab47e200-f833-4e8c-81f9-c63c5b3fc350"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.spatial.distance import euclidean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "467600d8-a6e3-48a5-ae29-9163abaee377",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "467600d8-a6e3-48a5-ae29-9163abaee377",
        "outputId": "cb1480f9-71f4-44b5-edd5-87d691721a31",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              ID  travel_fee             departure_time  \\\n",
            "0  2013-07-02 19:54:00.000000232         7.0  2013-07-02 19:54:00+00:00   \n",
            "1    2013-09-28 00:21:31.0000002         5.5  2013-09-28 00:21:31+00:00   \n",
            "2  2013-06-16 03:18:00.000000150        21.5  2013-06-16 03:18:00+00:00   \n",
            "3  2013-07-20 13:43:00.000000121         9.5  2013-07-20 13:43:00+00:00   \n",
            "4    2013-11-05 22:57:17.0000003        15.5  2013-11-05 22:57:17+00:00   \n",
            "\n",
            "   departure_long  departure_lat  arrival_long  arrival_lat  occupancy  \n",
            "0      -74.005360      40.728867    -74.008913    40.710907          1  \n",
            "1      -74.014165      40.708941    -74.016310    40.716734          1  \n",
            "2      -73.991075      40.760352    -73.941382    40.713292          1  \n",
            "3      -74.002662      40.723630    -73.991722    40.748905          5  \n",
            "4      -73.962397      40.712705    -73.996834    40.680403          2  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2596558 entries, 0 to 2596557\n",
            "Data columns (total 8 columns):\n",
            " #   Column          Dtype  \n",
            "---  ------          -----  \n",
            " 0   ID              object \n",
            " 1   travel_fee      float64\n",
            " 2   departure_time  object \n",
            " 3   departure_long  float64\n",
            " 4   departure_lat   float64\n",
            " 5   arrival_long    float64\n",
            " 6   arrival_lat     float64\n",
            " 7   occupancy       int64  \n",
            "dtypes: float64(5), int64(1), object(2)\n",
            "memory usage: 158.5+ MB\n",
            "None\n",
            "         travel_fee  departure_long  departure_lat  arrival_long  \\\n",
            "count  2.596558e+06    2.596558e+06   2.596558e+06  2.596514e+06   \n",
            "mean   1.259551e+01   -7.243741e+01   3.974318e+01 -7.239685e+01   \n",
            "std    1.081654e+01    1.125115e+01   9.133454e+00  1.143503e+01   \n",
            "min   -5.200000e+01   -7.400217e+02  -3.124490e+03 -1.216417e+03   \n",
            "25%    6.500000e+00   -7.399220e+01   4.073442e+01 -7.399147e+01   \n",
            "50%    9.500000e+00   -7.398186e+01   4.075236e+01 -7.398023e+01   \n",
            "75%    1.400000e+01   -7.396680e+01   4.076704e+01 -7.396362e+01   \n",
            "max    5.000000e+02    8.343336e+01   2.342817e+03  1.428740e+03   \n",
            "\n",
            "        arrival_lat     occupancy  \n",
            "count  2.596514e+06  2.596558e+06  \n",
            "mean   3.972336e+01  1.709320e+00  \n",
            "std    8.438912e+00  1.375425e+00  \n",
            "min   -3.111707e+03  0.000000e+00  \n",
            "25%    4.073352e+01  1.000000e+00  \n",
            "50%    4.075279e+01  1.000000e+00  \n",
            "75%    4.076779e+01  2.000000e+00  \n",
            "max    4.739714e+02  9.000000e+00  \n"
          ]
        }
      ],
      "source": [
        "# Creating a DataFrame from a CSV file\n",
        "transport = pd.read_csv('dataset.csv')\n",
        "\n",
        "#Take a quick look at the data such as using head, describe, info\n",
        "print(transport.head())\n",
        "print(transport.info())\n",
        "print(transport.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "894e258a-f130-4688-936c-1445ea20bc7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "894e258a-f130-4688-936c-1445ea20bc7d",
        "outputId": "04ab5883-9598-4900-f97e-09e124de8d59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unique values in ID\n",
            "['2013-07-02 19:54:00.000000232' '2013-09-28 00:21:31.0000002'\n",
            " '2013-06-16 03:18:00.000000150' ... '2013-05-25 14:48:39.0000002'\n",
            " '2013-12-22 20:45:19.0000001' '2013-07-17 18:57:14.0000003']\n",
            "Value counts:\n",
            "2013-07-02 19:54:00.000000232    1\n",
            "2013-12-17 07:31:00.00000095     1\n",
            "2013-03-03 22:16:00.00000070     1\n",
            "2013-01-01 11:16:16.0000001      1\n",
            "2013-08-07 23:54:40.0000002      1\n",
            "                                ..\n",
            "2013-06-22 12:05:00.00000049     1\n",
            "2013-03-20 12:42:00.000000144    1\n",
            "2013-05-14 00:54:28.0000002      1\n",
            "2013-12-16 19:45:00.00000087     1\n",
            "2013-07-17 18:57:14.0000003      1\n",
            "Name: ID, Length: 2596558, dtype: int64\n",
            "\n",
            "Unique values in departure_time\n",
            "['2013-07-02 19:54:00+00:00' '2013-09-28 00:21:31+00:00'\n",
            " '2013-06-16 03:18:00+00:00' ... '2013-04-17 10:34:24+00:00'\n",
            " '2013-05-25 14:48:39+00:00' '2013-12-22 20:45:19+00:00']\n",
            "Value counts:\n",
            "2013-07-24 18:55:00+00:00    22\n",
            "2013-04-26 22:04:00+00:00    22\n",
            "2013-03-21 22:01:00+00:00    22\n",
            "2013-05-03 10:47:00+00:00    21\n",
            "2013-08-09 18:53:00+00:00    21\n",
            "                             ..\n",
            "2013-08-14 04:02:04+00:00     1\n",
            "2013-05-24 00:59:48+00:00     1\n",
            "2013-02-27 12:31:05+00:00     1\n",
            "2013-05-23 22:31:32+00:00     1\n",
            "2013-12-22 20:45:19+00:00     1\n",
            "Name: departure_time, Length: 1448091, dtype: int64\n",
            "\n",
            "Statistics for travel_fee\n",
            "Minimum: -52.0\n",
            "Maximum: 500.0\n",
            "Mean: 12.59550563091601\n",
            "Standard deviation: 10.816536706348616\n",
            "\n",
            "Statistics for departure_long\n",
            "Minimum: -740.021667\n",
            "Maximum: 83.433358\n",
            "Mean: -72.43741222188717\n",
            "Standard deviation: 11.251152443616792\n",
            "\n",
            "Statistics for departure_lat\n",
            "Minimum: -3124.489865\n",
            "Maximum: 2342.816667\n",
            "Mean: 39.74318142067922\n",
            "Standard deviation: 9.13345364779934\n",
            "\n",
            "Statistics for arrival_long\n",
            "Minimum: -1216.416667\n",
            "Maximum: 1428.740223\n",
            "Mean: -72.39684941407366\n",
            "Standard deviation: 11.435030146009414\n",
            "\n",
            "Statistics for arrival_lat\n",
            "Minimum: -3111.70716\n",
            "Maximum: 473.971373\n",
            "Mean: 39.72336157377968\n",
            "Standard deviation: 8.438911879313457\n",
            "\n",
            "Statistics for occupancy\n",
            "Minimum: 0\n",
            "Maximum: 9\n",
            "Mean: 1.7093201846444408\n",
            "Standard deviation: 1.3754253772616316\n"
          ]
        }
      ],
      "source": [
        "# Exploring categorical variables\n",
        "categorical_columns = ['ID','departure_time']\n",
        "for column in categorical_columns:\n",
        "    print(\"\\nUnique values in\", column)\n",
        "    print(transport[column].unique())\n",
        "    print(\"Value counts:\")\n",
        "    print(transport[column].value_counts())\n",
        "\n",
        "# Analyzing numerical variables\n",
        "numerical_columns = ['travel_fee','departure_long',\"departure_lat\",'arrival_long','arrival_lat', 'occupancy']\n",
        "\n",
        "for column in numerical_columns:\n",
        "    print(\"\\nStatistics for\", column)\n",
        "    print(\"Minimum:\", transport[column].min())\n",
        "    print(\"Maximum:\", transport[column].max())\n",
        "    print(\"Mean:\", transport[column].mean())\n",
        "    print(\"Standard deviation:\", transport[column].std())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63b382dc-b46b-4741-9e23-ff390e64f95c",
      "metadata": {
        "id": "63b382dc-b46b-4741-9e23-ff390e64f95c"
      },
      "source": [
        "### Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2322923c-2c79-4293-bef2-2095c6989df5",
      "metadata": {
        "id": "2322923c-2c79-4293-bef2-2095c6989df5"
      },
      "outputs": [],
      "source": [
        "#Diagram 1 Departure longtitude and longtitude\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(transport['departure_long'], transport['departure_lat'] , alpha=0.1)\n",
        "plt.xlabel('Departure Longitude')\n",
        "plt.ylabel('Departure Latitude')\n",
        "plt.title('Scatter Plot of Taxi Ride Starting Points')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d33aa1a9-146e-4a94-9cc9-894385b6507c",
      "metadata": {
        "id": "d33aa1a9-146e-4a94-9cc9-894385b6507c"
      },
      "outputs": [],
      "source": [
        "# Diagram 2 Distribution of travel fees\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=transport, x='travel_fee', bins=20, kde=True)\n",
        "plt.title('Distribution of Travel Fees')\n",
        "plt.xlabel('Travel Fee')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlim(0, 100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7782dd8b-d20d-478c-abdd-eb4198b9a233",
      "metadata": {
        "id": "7782dd8b-d20d-478c-abdd-eb4198b9a233"
      },
      "outputs": [],
      "source": [
        "#Diagram 3 Departure and Arrival Locations\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=transport, x='departure_long', y='departure_lat', label='Departure')\n",
        "sns.scatterplot(data=transport, x='arrival_long', y='arrival_lat', label='Arrival')\n",
        "plt.title('Departure and Arrival Locations')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb2c489d-14d4-49b0-b392-255160517138",
      "metadata": {
        "id": "fb2c489d-14d4-49b0-b392-255160517138"
      },
      "outputs": [],
      "source": [
        "# Diagram 4 Boxplot of travel fees by occupancy\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=transport, x='occupancy', y='travel_fee')\n",
        "plt.title('Travel Fees by Occupancy')\n",
        "plt.xlabel('Occupancy')\n",
        "plt.ylabel('Travel Fee')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccd83de8-f14f-478e-982d-4ea87f73289e",
      "metadata": {
        "id": "ccd83de8-f14f-478e-982d-4ea87f73289e"
      },
      "outputs": [],
      "source": [
        "# Diagram 5 Average travel fee by occupancy\n",
        "avg_fee_by_occupancy = transport.groupby('occupancy')['travel_fee'].mean()\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=avg_fee_by_occupancy.index, y=avg_fee_by_occupancy.values)\n",
        "plt.title('Average Travel Fee by Occupancy')\n",
        "plt.xlabel('Occupancy')\n",
        "plt.ylabel('Average Travel Fee')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d01a6771-8878-4db0-9802-0e29ddf0d524",
      "metadata": {
        "id": "d01a6771-8878-4db0-9802-0e29ddf0d524"
      },
      "source": [
        "### Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e00c6b32-78d3-439e-8ffd-d0bb6f16181c",
      "metadata": {
        "id": "e00c6b32-78d3-439e-8ffd-d0bb6f16181c"
      },
      "outputs": [],
      "source": [
        "corr_matrix = transport.corr(numeric_only=True)\n",
        "corr_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = transport[numerical_columns].corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')"
      ],
      "metadata": {
        "id": "WFKvzVUY3BPY"
      },
      "id": "WFKvzVUY3BPY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7c617274-732e-4f93-b681-4bc58acd0a66",
      "metadata": {
        "id": "7c617274-732e-4f93-b681-4bc58acd0a66"
      },
      "source": [
        "### Query Date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c05a773b-2732-4282-90a1-bef41ca5cc38",
      "metadata": {
        "id": "c05a773b-2732-4282-90a1-bef41ca5cc38"
      },
      "outputs": [],
      "source": [
        "# 1. Query to find the average travel fee:\n",
        "average_travel_fee = transport['travel_fee'].mean()\n",
        "print(\"Average Travel Fee:\", average_travel_fee)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7858b9a2-c367-449b-a99b-9ca8bd2101b3",
      "metadata": {
        "id": "7858b9a2-c367-449b-a99b-9ca8bd2101b3"
      },
      "outputs": [],
      "source": [
        "# 2. Query to find the most common departure hour:\n",
        "transport['departure_hour'] = pd.to_datetime(transport['departure_time']).dt.hour\n",
        "most_common_departure_hour = transport['departure_hour'].mode()[0]\n",
        "print(\"Most Common Departure Hour:\", most_common_departure_hour)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d79e1a01-0995-481e-a23b-fca00afc644e",
      "metadata": {
        "id": "d79e1a01-0995-481e-a23b-fca00afc644e"
      },
      "outputs": [],
      "source": [
        "# Query 3: Travel Fee Range\n",
        "min_travel_fee = transport['travel_fee'].min()\n",
        "max_travel_fee = transport['travel_fee'].max()\n",
        "print(\"Travel Fee Range: {} - {}\".format(min_travel_fee, max_travel_fee))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6f7e2af-2ca0-49cf-b3fc-f7d04783cb1e",
      "metadata": {
        "id": "e6f7e2af-2ca0-49cf-b3fc-f7d04783cb1e"
      },
      "outputs": [],
      "source": [
        "# Query 4: Average Travel Fee by Occupancy\n",
        "average_fee_by_occupancy = transport.groupby('occupancy')['travel_fee'].mean()\n",
        "print(\"Average Travel Fee by Occupancy:\")\n",
        "print(average_fee_by_occupancy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbe4688a-f285-4b77-87f1-d4c8d139b327",
      "metadata": {
        "id": "bbe4688a-f285-4b77-87f1-d4c8d139b327"
      },
      "outputs": [],
      "source": [
        "# Query 5: Average Travel Fee by Hour\n",
        "transport['departure_time'] = pd.to_datetime(transport['departure_time'])\n",
        "transport['hour'] = transport['departure_time'].dt.hour\n",
        "average_fee_by_hour = transport.groupby('hour')['travel_fee'].mean()\n",
        "print(\"Average Travel Fee by Hour:\")\n",
        "print(average_fee_by_hour)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0b247b6-3a12-421d-9519-236d6f5fa786",
      "metadata": {
        "id": "d0b247b6-3a12-421d-9519-236d6f5fa786"
      },
      "outputs": [],
      "source": [
        "# Query 6: Busiest Departure Locations\n",
        "most_common_departures = transport.groupby(['departure_lat', 'departure_long']).size().nlargest(5)\n",
        "print(\"Busiest Departure Locations:\")\n",
        "print(most_common_departures)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77d05ca0-34e0-49b2-b1af-b9fb34d1ada9",
      "metadata": {
        "id": "77d05ca0-34e0-49b2-b1af-b9fb34d1ada9"
      },
      "outputs": [],
      "source": [
        "# Query 7: Popular Travel Routes\n",
        "popular_routes = transport.groupby(['departure_lat', 'departure_long', 'arrival_lat', 'arrival_long']).size().nlargest(5)\n",
        "print(\"Popular Travel Routes:\")\n",
        "print(popular_routes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5a6f1cf-b9ca-4a19-ab51-7f5188e7f0cb",
      "metadata": {
        "id": "b5a6f1cf-b9ca-4a19-ab51-7f5188e7f0cb"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de0c6bbf-c9eb-4bdd-a9ec-dfe8f53642f3",
      "metadata": {
        "id": "de0c6bbf-c9eb-4bdd-a9ec-dfe8f53642f3"
      },
      "outputs": [],
      "source": [
        "sample_size = min(500000, len(transport))\n",
        "transport = transport.sample(n=sample_size)\n",
        "\n",
        "\n",
        "travelfee_train, travelfee_test = train_test_split(transport, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Length of travelfee_train:\", len(travelfee_train))\n",
        "print(\"Length of travelfee_test:\", len(travelfee_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4858df9f-797b-44fd-90a8-2832b110b207",
      "metadata": {
        "id": "4858df9f-797b-44fd-90a8-2832b110b207"
      },
      "outputs": [],
      "source": [
        "#check is there any data is null value\n",
        "travelfee_train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee5c5a9a-3d45-4ff1-ab88-52e9763c120c",
      "metadata": {
        "id": "ee5c5a9a-3d45-4ff1-ab88-52e9763c120c"
      },
      "outputs": [],
      "source": [
        "#handling missing value\n",
        "travelfee_train[\"departure_long\"].fillna(travelfee_train[\"departure_long\"].mean(), inplace=True)\n",
        "travelfee_train[\"departure_lat\"].fillna(travelfee_train[\"departure_lat\"].mean(), inplace=True)\n",
        "travelfee_train[\"occupancy\"].fillna(travelfee_train[\"occupancy\"].mode()[0], inplace=True)\n",
        "travelfee_train.drop(columns=['ID'], inplace=True)\n",
        "\n",
        "# Drop rows with missing \"departure_time\",\"arrival_long\" and \"arrival_lat\"\n",
        "travelfee_train.dropna(subset=[\"departure_time\", \"arrival_long\", \"arrival_lat\"],inplace = True)\n",
        "travelfee_train.isnull().sum()\n",
        "\n",
        "# Drop rows with a 0 value of occupancy\n",
        "travelfee_train = travelfee_train.drop(travelfee_train[travelfee_train['occupancy'] <= 0].index)\n",
        "\n",
        "# Handling Outliers\n",
        "# Select columns for numeric attributes\n",
        "num_attribs = ['departure_long', 'departure_lat', 'arrival_long', 'arrival_lat', 'occupancy', 'travel_fee']\n",
        "\n",
        "# Remove outliers using Z-score method\n",
        "z_scores = np.abs((travelfee_train[num_attribs] - travelfee_train[num_attribs].mean()) / travelfee_train[num_attribs].std())\n",
        "travelfee_train = travelfee_train[(z_scores < 3).all(axis=1)]\n",
        "travelfee_train.info()\n",
        "travelfee_train\n",
        "\n",
        "# Filter out rows with 0 values in departure_long, departure_lat, arrival_long, and arrival_lat\n",
        "travelfee_train = travelfee_train[\n",
        "    (travelfee_train[\"departure_long\"] != 0) &\n",
        "    (travelfee_train[\"departure_lat\"] != 0) &\n",
        "    (travelfee_train[\"arrival_long\"] != 0) &\n",
        "    (travelfee_train[\"arrival_lat\"] != 0)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d934079f-7ad7-4dc8-891f-d6318119a683",
      "metadata": {
        "id": "d934079f-7ad7-4dc8-891f-d6318119a683"
      },
      "outputs": [],
      "source": [
        "# Convert departure_time to datetime\n",
        "travelfee_train['departure_time'] = pd.to_datetime(travelfee_train['departure_time'])\n",
        "\n",
        "# Extract features from departure_time\n",
        "travelfee_train['hour_of_day'] = travelfee_train['departure_time'].dt.hour\n",
        "travelfee_train['day_of_week'] = travelfee_train['departure_time'].dt.dayofweek\n",
        "\n",
        "# Calculate Euclidean distance between departure and arrival locations\n",
        "travelfee_train['distance'] = travelfee_train.apply(lambda row: euclidean((row['departure_lat'], row['departure_long']),\n",
        "                                                             (row['arrival_lat'], row['arrival_long'])), axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72eaf15a-79fd-4faf-a909-093e147e71ee",
      "metadata": {
        "id": "72eaf15a-79fd-4faf-a909-093e147e71ee"
      },
      "outputs": [],
      "source": [
        "travelfee_train.info()\n",
        "travelfee_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "846e2e7b-683c-4723-9826-f80767d4cf0e",
      "metadata": {
        "id": "846e2e7b-683c-4723-9826-f80767d4cf0e"
      },
      "outputs": [],
      "source": [
        "travelfee = travelfee_train[['hour_of_day', 'day_of_week','occupancy','distance']]\n",
        "travelfee_labels = travelfee_train[\"travel_fee\"].copy()\n",
        "x1_train, x1_test, y1_train, y1_test = train_test_split(travelfee, travelfee_labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7060ec02-4e4d-440d-861d-1c750f78f3db",
      "metadata": {
        "id": "7060ec02-4e4d-440d-861d-1c750f78f3db"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "num_attribs = [ 'hour_of_day', 'day_of_week','occupancy','distance' ]\n",
        "\n",
        "num_pipeline = make_pipeline(\n",
        "    StandardScaler()  # Scale features\n",
        ")\n",
        "preprocessing = ColumnTransformer([\n",
        "    (\"num\", num_pipeline, num_attribs),\n",
        "    # Apply numeric pipeline to numeric attributes\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "125927e1-1294-49d7-b328-9fc01f8afbe5",
      "metadata": {
        "id": "125927e1-1294-49d7-b328-9fc01f8afbe5"
      },
      "outputs": [],
      "source": [
        "transport_prepared = preprocessing.fit_transform(travelfee)\n",
        "transport_prepared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff7bf841-4eef-43be-8929-71f45967dd69",
      "metadata": {
        "id": "ff7bf841-4eef-43be-8929-71f45967dd69"
      },
      "outputs": [],
      "source": [
        "preprocessing.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58b77fb4-5e1e-428d-882f-d81c0b2128c2",
      "metadata": {
        "id": "58b77fb4-5e1e-428d-882f-d81c0b2128c2"
      },
      "source": [
        "### Visualisation and Query after Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73122838-b70d-4fb1-aa83-788d02ff4e46",
      "metadata": {
        "id": "73122838-b70d-4fb1-aa83-788d02ff4e46"
      },
      "outputs": [],
      "source": [
        "# Diagram 1 Average travel fee by occupancy\n",
        "avg_fee_by_occupancy = travelfee_train.groupby('occupancy')['travel_fee'].mean()\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=avg_fee_by_occupancy.index, y=avg_fee_by_occupancy.values)\n",
        "plt.title('Average Travel Fee by Occupancy')\n",
        "plt.xlabel('Occupancy')\n",
        "plt.ylabel('Average Travel Fee')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f87c6deb-4835-4b26-84b7-7bd56cf26bf9",
      "metadata": {
        "id": "f87c6deb-4835-4b26-84b7-7bd56cf26bf9"
      },
      "outputs": [],
      "source": [
        "#Diagram 2 Departure and Arrival Locations\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=travelfee_train, x='departure_long', y='departure_lat', label='Departure')\n",
        "sns.scatterplot(data=travelfee_train, x='arrival_long', y='arrival_lat', label='Arrival')\n",
        "plt.title('Departure and Arrival Locations')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d039770a-bb77-457b-9a9a-2bbd9d345edf",
      "metadata": {
        "id": "d039770a-bb77-457b-9a9a-2bbd9d345edf"
      },
      "outputs": [],
      "source": [
        "# Query 1. Query to find the most common departure hour:\n",
        "travelfee_train['departure_hour'] = pd.to_datetime(travelfee_train['departure_time']).dt.hour\n",
        "most_common_departure_hour = travelfee_train['departure_hour'].mode()[0]\n",
        "print(\"Most Common Departure Hour:\", most_common_departure_hour)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a262fc62-4cd4-4c4e-8e5a-58f1215ea28c",
      "metadata": {
        "id": "a262fc62-4cd4-4c4e-8e5a-58f1215ea28c"
      },
      "outputs": [],
      "source": [
        "# Query 2: Average Travel Fee by Occupancy\n",
        "average_fee_by_occupancy = travelfee_train.groupby('occupancy')['travel_fee'].mean()\n",
        "print(\"Average Travel Fee by Occupancy:\")\n",
        "print(average_fee_by_occupancy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28efd61b-3858-41ce-86ae-e7b55774d609",
      "metadata": {
        "id": "28efd61b-3858-41ce-86ae-e7b55774d609"
      },
      "outputs": [],
      "source": [
        "# Query 3: Average Travel Fee by Hour\n",
        "travelfee_train['departure_time'] = pd.to_datetime(travelfee_train['departure_time'])\n",
        "travelfee_train['hour'] = travelfee_train['departure_time'].dt.hour\n",
        "average_fee_by_hour = travelfee_train.groupby('hour')['travel_fee'].mean()\n",
        "print(\"Average Travel Fee by Hour:\")\n",
        "print(average_fee_by_hour)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d7894de-6e5a-471f-8237-a7131a53f2b2",
      "metadata": {
        "id": "0d7894de-6e5a-471f-8237-a7131a53f2b2"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e416deed-d522-413f-b7f4-b99585dba029",
      "metadata": {
        "id": "e416deed-d522-413f-b7f4-b99585dba029"
      },
      "source": [
        "### Model 1: Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3d961d3-20d3-49bd-8a54-59f5a642ecd6",
      "metadata": {
        "id": "e3d961d3-20d3-49bd-8a54-59f5a642ecd6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#Predict fair price\n",
        "#Model 1: Random Reofest Regressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "forest_reg = make_pipeline(\n",
        "    preprocessing,\n",
        "    RandomForestRegressor(random_state=42)\n",
        ")\n",
        "\n",
        "forest_rmses = -cross_val_score(forest_reg, x1_train, y1_train,\n",
        "                                scoring=\"neg_root_mean_squared_error\",\n",
        "                                cv=3)\n",
        "forest_rmses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a736655-4548-40ab-901b-c15ef8a63ab4",
      "metadata": {
        "id": "0a736655-4548-40ab-901b-c15ef8a63ab4"
      },
      "outputs": [],
      "source": [
        "pd.Series(forest_rmses).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45d52f9a-8bb6-4344-b53b-985cf0f5c27e",
      "metadata": {
        "id": "45d52f9a-8bb6-4344-b53b-985cf0f5c27e"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "forest_rmses = cross_validate(forest_reg,\n",
        "                              x1_train, y1_train,\n",
        "                              scoring=\"neg_root_mean_squared_error\",\n",
        "                              cv=2,\n",
        "                              return_train_score=True)\n",
        "\n",
        "forest_rmses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8075ce7-6b09-4744-93b1-77afa9547d8d",
      "metadata": {
        "id": "f8075ce7-6b09-4744-93b1-77afa9547d8d"
      },
      "outputs": [],
      "source": [
        "forest_reg.fit(x1_train, y1_train)\n",
        "travelfee_predictions = forest_reg.predict(x1_train)\n",
        "forest_rmse = mean_squared_error(y1_train,\n",
        "                                 travelfee_predictions,\n",
        "                                 squared=False)\n",
        "forest_rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7892b4f2-21eb-4374-9c4d-34b008bb61e2",
      "metadata": {
        "id": "7892b4f2-21eb-4374-9c4d-34b008bb61e2"
      },
      "outputs": [],
      "source": [
        "# Create a scatter plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=y1_train, y=travelfee_predictions)\n",
        "plt.xlabel('Actual Travel Fee')\n",
        "plt.ylabel('Predicted Travel Fee')\n",
        "plt.title('Actual vs. Predicted Travel Fee')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e646a90f-b2ba-4183-94b0-8192cc6ffa7d",
      "metadata": {
        "id": "e646a90f-b2ba-4183-94b0-8192cc6ffa7d"
      },
      "outputs": [],
      "source": [
        "# Feature Importance Bar Plot:\n",
        "# Get feature importances from the trained Random Forest model\n",
        "feature_importances = forest_reg.named_steps['randomforestregressor'].feature_importances_\n",
        "\n",
        "# Create a bar plot of feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=feature_importances, y=num_attribs)\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importances')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d254e68-9aa9-4f8e-9885-252e6e3d6c63",
      "metadata": {
        "id": "1d254e68-9aa9-4f8e-9885-252e6e3d6c63"
      },
      "outputs": [],
      "source": [
        "#Learning Curve\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    forest_reg, x1_train, y1_train, cv=2, scoring='neg_mean_squared_error'\n",
        ")\n",
        "\n",
        "# Calculate mean and standard deviation of scores\n",
        "train_scores_mean = -train_scores.mean(axis=1)\n",
        "test_scores_mean = -test_scores.mean(axis=1)\n",
        "\n",
        "# Create learning curve plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_sizes, train_scores_mean, label='Train')\n",
        "plt.plot(train_sizes, test_scores_mean, label='Validation')\n",
        "plt.xlabel('Training Set Size')\n",
        "plt.ylabel('Negative Mean Squared Error')\n",
        "plt.title('Learning Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fac30ca-7bb5-4ace-8528-676505b8bf05",
      "metadata": {
        "id": "2fac30ca-7bb5-4ace-8528-676505b8bf05"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame to display actual and predicted prices\n",
        "result_df = pd.DataFrame({\n",
        "    'Actual Price': y1_train,\n",
        "    'Predicted Price': travelfee_predictions\n",
        "})\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(result_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbc1e8ee-3940-453c-b1d7-4d6086ceafe2",
      "metadata": {
        "id": "bbc1e8ee-3940-453c-b1d7-4d6086ceafe2"
      },
      "source": [
        "### Random Forest Regressor Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdf31600-4ae3-4998-bcd5-e60d6ad317da",
      "metadata": {
        "id": "bdf31600-4ae3-4998-bcd5-e60d6ad317da"
      },
      "outputs": [],
      "source": [
        "### Model 1: Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c643c9c3-350e-4a3e-8473-6f8360a8943a",
      "metadata": {
        "id": "c643c9c3-350e-4a3e-8473-6f8360a8943a"
      },
      "outputs": [],
      "source": [
        "rf_regressor = RandomForestRegressor(random_state=42)\n",
        "# Create a pipeline with preprocessing and random forest regressor\n",
        "rf_full_pipeline = Pipeline([\n",
        "    (\"preprocessing\", preprocessing),\n",
        "    (\"rf_reg\", rf_regressor),\n",
        "])\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_distributions = [\n",
        "    {'rf_reg__n_estimators': [100, 200, 300],\n",
        "     'rf_reg__max_depth': [None, 10, 20],\n",
        "     'rf_reg__min_samples_split': [2, 5, 10]}\n",
        "]\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search_rf = GridSearchCV(rf_full_pipeline, param_distributions, cv=2, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Assuming 'travelfee' is your feature data and 'travelfee_labels' are the target labels\n",
        "grid_search_rf.fit(x1_train, y1_train)\n",
        "\n",
        "# Calculate RMSE and standard deviation of RMSE for grid search\n",
        "grid_rmse_scores = np.sqrt(-grid_search_rf.cv_results_['mean_test_score'])\n",
        "grid_rmse_mean = np.mean(grid_rmse_scores)\n",
        "grid_rmse_std = np.std(grid_rmse_scores)\n",
        "\n",
        "\n",
        "# Print the results\n",
        "print(\"Grid Search RMSE - Mean:\", grid_rmse_mean)\n",
        "print(\"Grid Search RMSE - Standard Deviation:\", grid_rmse_std)\n",
        "# Print best parameters\n",
        "print(\"Tuned hyperparameters (best parameters):\", grid_search_rf.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Get the best model from grid search\n",
        "best_rf_model = grid_search_rf.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y1_pred = best_rf_model.predict(x1_test)\n",
        "\n",
        "# Calculate RMSE on the test set\n",
        "test_rmse = np.sqrt(mean_squared_error(y1_test, y1_pred))\n",
        "\n",
        "# Calculate RMSE scores for all cross-validation folds\n",
        "grid_rmse_scores = np.sqrt(-grid_search_rf.cv_results_['mean_test_score'])\n",
        "\n",
        "# Calculate mean RMSE\n",
        "grid_rmse_mean = np.mean(grid_rmse_scores)\n",
        "\n",
        "# Calculate standard deviation of RMSE\n",
        "grid_rmse_std = np.std(grid_rmse_scores)\n",
        "\n",
        "# Print the results\n",
        "print(\"Test RMSE:\", test_rmse)\n",
        "print(\"Grid Search RMSE - Mean:\", grid_rmse_mean)\n",
        "print(\"Grid Search RMSE - Standard Deviation:\",grid_rmse_std)\n"
      ],
      "metadata": {
        "id": "G-bvlGI0JS_H"
      },
      "id": "G-bvlGI0JS_H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b61eba53-5804-45e5-8bee-c37cc6acf82d",
      "metadata": {
        "id": "b61eba53-5804-45e5-8bee-c37cc6acf82d"
      },
      "source": [
        "### Model 2: Ridge Refression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e63034d-fe5b-4b4d-bd17-6439ba229b34",
      "metadata": {
        "id": "2e63034d-fe5b-4b4d-bd17-6439ba229b34"
      },
      "outputs": [],
      "source": [
        "#Predict fair price\n",
        "#Model 2: Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m7SA38l9XDk9",
      "metadata": {
        "id": "m7SA38l9XDk9"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "# Create and train Ridge Regression model\n",
        "ridge_model = Ridge(alpha=1.0)\n",
        "ridge_model.fit(x1_train, y1_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OnbRI7u7XERk",
      "metadata": {
        "id": "OnbRI7u7XERk"
      },
      "outputs": [],
      "source": [
        "ridge_score = cross_val_score(ridge_model, x1_train, y1_train, cv=5,verbose=2)\n",
        "print(\"Ridge Score: \", ridge_score)\n",
        "print(ridge_score.mean(),ridge_score.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qIe7M6-bYIVD",
      "metadata": {
        "id": "qIe7M6-bYIVD"
      },
      "source": [
        "### Ridge Regression Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9riIowbQX-o0",
      "metadata": {
        "id": "9riIowbQX-o0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YFQdpNcPYeQT",
      "metadata": {
        "id": "YFQdpNcPYeQT"
      },
      "outputs": [],
      "source": [
        "# Define the hyperparameters grid\n",
        "parameters = {\"alpha\": [0.001, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.08, 1, 2, 3, 5, 8, 10, 20, 50, 100]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_KNPvGUNYd1P",
      "metadata": {
        "id": "_KNPvGUNYd1P"
      },
      "outputs": [],
      "source": [
        "# Create Ridge regression model\n",
        "ridge_cv = GridSearchCV(Ridge(), parameters, scoring='neg_mean_squared_error', cv=10)\n",
        "ridge_cv.fit(x1_train, y1_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TIzR6K0hYdpk",
      "metadata": {
        "id": "TIzR6K0hYdpk"
      },
      "outputs": [],
      "source": [
        "# Get the best Ridge model\n",
        "best_ridge = ridge_cv.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ikbjRb9cYhzz",
      "metadata": {
        "id": "ikbjRb9cYhzz"
      },
      "outputs": [],
      "source": [
        "# Calculate RMSE for each fold and mean RMSE\n",
        "mse_scores = -ridge_cv.cv_results_['mean_test_score']\n",
        "rmse_scores = np.sqrt(mse_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc6jWdqnYkWf",
      "metadata": {
        "id": "bc6jWdqnYkWf"
      },
      "outputs": [],
      "source": [
        "# Print best hyperparameters and evaluation metrics\n",
        "print(\"Best Hyperparameters:\", ridge_cv.best_params_)\n",
        "print(\"Mean RMSE:\", np.mean(rmse_scores))\n",
        "print(\"Standard Deviation of RMSE:\", np.std(rmse_scores))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid for Ridge Regression\n",
        "parameters = {\n",
        "    'alpha': [0.001, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.08, 1, 2, 3, 5, 8, 10, 20, 50, 100],\n",
        "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation for Ridge Regression\n",
        "ridge_cv = GridSearchCV(Ridge(), parameters, scoring='neg_mean_squared_error', cv=10)\n",
        "ridge_cv.fit(x1_train, y1_train)\n",
        "\n",
        "# Get the best Ridge model from grid search\n",
        "best_ridge = ridge_cv.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y1_pred_ridge = best_ridge.predict(x1_test)\n",
        "\n",
        "# Calculate RMSE on the test set for Ridge Regression\n",
        "test_rmse_ridge = np.sqrt(mean_squared_error(y1_test, y1_pred_ridge))\n",
        "\n",
        "# Calculate mean squared error scores and RMSE scores for Ridge Regression\n",
        "mse_scores_ridge = -ridge_cv.cv_results_['mean_test_score']\n",
        "rmse_scores_ridge = np.sqrt(mse_scores_ridge)\n",
        "\n",
        "# Calculate standard deviation of RMSE scores for Ridge Regression\n",
        "rmse_std_ridge = np.std(rmse_scores_ridge)\n",
        "\n",
        "# Print RMSE and standard deviation of RMSE for Ridge Regression\n",
        "print(\"Ridge Regression Test RMSE:\", test_rmse_ridge)\n",
        "print(\"Ridge Regression Grid Search RMSE - Mean:\", np.mean(rmse_scores_ridge))\n",
        "print(\"Ridge Regression Grid Search RMSE - Standard Deviation:\",rmse_std_ridge)"
      ],
      "metadata": {
        "id": "UgmoUMgyJaSJ"
      },
      "id": "UgmoUMgyJaSJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "DQ07WpZ0J1V4",
      "metadata": {
        "id": "DQ07WpZ0J1V4"
      },
      "source": [
        "### Model 3: Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1XO4dAnjJypB",
      "metadata": {
        "id": "1XO4dAnjJypB"
      },
      "outputs": [],
      "source": [
        "#Predict fair price\n",
        "#Model 3: Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_mbqKOlWJ3_7",
      "metadata": {
        "id": "_mbqKOlWJ3_7"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "lasso_reg = make_pipeline(\n",
        "    preprocessing,\n",
        "    Lasso(alpha=0.01,random_state=42)\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BkOhzXlEJ5is",
      "metadata": {
        "id": "BkOhzXlEJ5is"
      },
      "outputs": [],
      "source": [
        "lasso_mse_scores = -cross_val_score(lasso_reg, x1_train, y1_train, scoring=\"neg_mean_squared_error\", cv=5)\n",
        "lasso_rmse_scores = np.sqrt(lasso_mse_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uf_9z8o8J77g",
      "metadata": {
        "id": "uf_9z8o8J77g"
      },
      "outputs": [],
      "source": [
        "lasso_mse = lasso_mse_scores.mean()\n",
        "\n",
        "# Print MSE and RMSE scores\n",
        "print(\"Lasso Regression Mean Squared Error (MSE):\", lasso_mse)\n",
        "print(\"Lasso Regression RMSE Scores:\", lasso_rmse_scores)\n",
        "print(\"Mean RMSE:\", lasso_rmse_scores.mean())\n",
        "print(\"Standard Deviation of RMSE:\", lasso_rmse_scores.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W1gl6HBeKCuB",
      "metadata": {
        "id": "W1gl6HBeKCuB"
      },
      "source": [
        "### Lasso Regression Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GJ6mKLbeKE8Z",
      "metadata": {
        "id": "GJ6mKLbeKE8Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UCzthD0JKF_S",
      "metadata": {
        "id": "UCzthD0JKF_S"
      },
      "outputs": [],
      "source": [
        "# Define the hyperparameters grid\n",
        "parameters = {\"alpha\": [0.001, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.08, 1, 2, 3, 5, 8, 10, 20, 50, 100]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_LHlV1VnKGu5",
      "metadata": {
        "id": "_LHlV1VnKGu5"
      },
      "outputs": [],
      "source": [
        "# Create lasso regression model\n",
        "lasso_cv = GridSearchCV(Lasso(), parameters, scoring='neg_mean_squared_error', cv=10)\n",
        "lasso_cv.fit(x1_train, y1_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eYg7TTs4KHtB",
      "metadata": {
        "id": "eYg7TTs4KHtB"
      },
      "outputs": [],
      "source": [
        "# Get the best Ridge model\n",
        "print(\"Best Parameters for Lasso Regression:\", lasso_cv.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BL8SDeB5KJqp",
      "metadata": {
        "id": "BL8SDeB5KJqp"
      },
      "outputs": [],
      "source": [
        "# Calculate RMSE for each fold and mean RMSE\n",
        "mse_scores = -lasso_cv.cv_results_['mean_test_score']\n",
        "rmse_scores = np.sqrt(mse_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BVFcKDK6KKRx",
      "metadata": {
        "id": "BVFcKDK6KKRx"
      },
      "outputs": [],
      "source": [
        "# Print best hyperparameters and evaluation metrics\n",
        "print(\"Best Hyperparameters:\", lasso_cv.best_params_)\n",
        "print(\"Mean RMSE:\", np.mean(rmse_scores))\n",
        "print(\"Standard Deviation of RMSE:\", np.std(rmse_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pMJx_3_DKLFp",
      "metadata": {
        "id": "pMJx_3_DKLFp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the grid search results\n",
        "results = lasso_cv.cv_results_\n",
        "alphas = lasso_cv.param_grid['alpha']\n",
        "neg_mse_means = -results['mean_test_score']\n",
        "neg_mse_stds = results['std_test_score']\n",
        "\n",
        "# Plot the mean negative MSE with error bars\n",
        "plt.errorbar(alphas, neg_mse_means, yerr=neg_mse_stds, marker='o')\n",
        "plt.xlabel('Alpha')\n",
        "plt.ylabel('Negative Mean Squared Error')\n",
        "plt.title('Grid Search Results for Lasso Regression')\n",
        "plt.xscale('log')  # Use a logarithmic scale for x-axis\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "evyvTrrXKNXJ",
      "metadata": {
        "id": "evyvTrrXKNXJ"
      },
      "outputs": [],
      "source": [
        "# Assuming lasso_cv is a fitted GridSearchCV object\n",
        "lasso_model = lasso_cv.best_estimator_  # Get the best-fitted Lasso model from the GridSearchCV\n",
        "\n",
        "# Assuming x1_test and y1_test are your test data\n",
        "lasso_predicted_fair_prices = lasso_model.predict(x1_test)\n",
        "\n",
        "# Plotting a graph to compare actual vs. predicted fair prices\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y1_test, lasso_predicted_fair_prices, alpha=0.5)\n",
        "plt.xlabel('Actual Fair Prices')\n",
        "plt.ylabel('Predicted Fair Prices (Lasso Regression)')\n",
        "plt.title('Actual vs. Predicted Fair Prices (Lasso Regression)')\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid for Lasso Regression\n",
        "parameters = {\n",
        "    'alpha': [0.001, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.08, 1, 2, 3, 5, 8, 10, 20, 50, 100],\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation for Lasso Regression\n",
        "lasso_cv = GridSearchCV(Lasso(), parameters, scoring='neg_mean_squared_error', cv=10)\n",
        "lasso_cv.fit(x1_train, y1_train)\n",
        "\n",
        "# Get the best Lasso model from grid search\n",
        "best_lasso = lasso_cv.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y1_pred_lasso = best_lasso.predict(x1_test)\n",
        "\n",
        "# Calculate RMSE on the test set for Lasso Regression\n",
        "test_rmse_lasso = np.sqrt(mean_squared_error(y1_test, y1_pred_lasso))\n",
        "\n",
        "# Calculate mean squared error scores and RMSE scores for Lasso Regression\n",
        "mse_scores_lasso = -lasso_cv.cv_results_['mean_test_score']\n",
        "rmse_scores_lasso = np.sqrt(mse_scores_lasso)\n",
        "\n",
        "# Calculate standard deviation of RMSE scores for Lasso Regression\n",
        "rmse_std_lasso = np.std(rmse_scores_lasso)\n",
        "\n",
        "# Print RMSE and standard deviation of RMSE for Lasso Regression\n",
        "print(\"Lasso Regression Test RMSE:\", test_rmse_lasso)\n",
        "print(\"Lasso Regression Grid Search RMSE - Mean:\", np.mean(rmse_scores_lasso))\n",
        "print(\"Lasso Regression Grid Search RMSE - Standard Deviation:\",rmse_std_lasso)"
      ],
      "metadata": {
        "id": "4KmgpAf6JoVB"
      },
      "id": "4KmgpAf6JoVB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2c200415-0950-4833-ae28-0337b9867060",
      "metadata": {
        "id": "2c200415-0950-4833-ae28-0337b9867060"
      },
      "source": [
        "### Model 4: Support Vector Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21cde661-3c62-4eb8-899a-615e87690f11",
      "metadata": {
        "id": "21cde661-3c62-4eb8-899a-615e87690f11"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "import numpy as np\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Choose a random subset of 10000 data points for training (to reduce the training time for this model)\n",
        "random_indices = np.random.choice(len(x1_train), size=10000, replace=False)\n",
        "x_subset_train = x1_train.iloc[random_indices]  # Use .iloc to index by positions\n",
        "y_subset_train = y1_train.iloc[random_indices]\n",
        "\n",
        "# Create the SVR model\n",
        "svr_model = make_pipeline(\n",
        "    preprocessing,\n",
        "    SVR()  # Remove random_state parameter\n",
        ")\n",
        "\n",
        "# Evaluate the model using cross-validation\n",
        "svr_rmses = -cross_val_score(svr_model, x_subset_train, y_subset_train,\n",
        "                             scoring=\"neg_root_mean_squared_error\",\n",
        "                             cv=10)\n",
        "print(\"Cross-Validation RMSEs:\", svr_rmses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0e53815-2a84-41aa-a26c-14773c6320ae",
      "metadata": {
        "id": "c0e53815-2a84-41aa-a26c-14773c6320ae"
      },
      "outputs": [],
      "source": [
        "# Fit the model on the subset of training data\n",
        "svr_model.fit(x_subset_train, y_subset_train)\n",
        "\n",
        "# Make predictions on the subset of training data\n",
        "travelfee_predictions = svr_model.predict(x_subset_train)\n",
        "\n",
        "# Calculate RMSE on the subset of training data\n",
        "svr_rmse = mean_squared_error(y_subset_train,\n",
        "                              travelfee_predictions,\n",
        "                              squared=False)\n",
        "print(\"Subset Training RMSE:\", svr_rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51a4c9ea-157e-4841-a34d-f0d976f6ad25",
      "metadata": {
        "id": "51a4c9ea-157e-4841-a34d-f0d976f6ad25"
      },
      "source": [
        "### Support Vector Regression Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e3287b1-f9a2-4832-b346-ac5e796fa9ef",
      "metadata": {
        "tags": [],
        "id": "6e3287b1-f9a2-4832-b346-ac5e796fa9ef"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.svm import SVR\n",
        "param_grid = {\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'C': [0.1, 1, 10],\n",
        "    'epsilon': [0.1, 0.2, 0.3, 0.4]\n",
        "}\n",
        "\n",
        "best_score = None\n",
        "best_params = None\n",
        "\n",
        "# Iterate through all combinations of hyperparameters\n",
        "for kernel in param_grid['kernel']:\n",
        "    for C in param_grid['C']:\n",
        "        for epsilon in param_grid['epsilon']:\n",
        "            svr = SVR(kernel=kernel, C=C, epsilon=epsilon)\n",
        "            scores = cross_val_score(svr, x_subset_train, y_subset_train, cv=5, scoring='neg_mean_squared_error')\n",
        "            avg_score = np.mean(scores)\n",
        "\n",
        "            # Check if the current combination is the best\n",
        "            if best_score is None or avg_score < best_score:\n",
        "                best_score = avg_score\n",
        "                best_params = {'kernel': kernel, 'C': C, 'epsilon': epsilon}\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_kernel = best_params['kernel']\n",
        "best_C = best_params['C']\n",
        "best_epsilon = best_params['epsilon']\n",
        "\n",
        "print(\"Best Kernel:\", best_params['kernel'])\n",
        "print(\"Best C:\", best_params['C'])\n",
        "print(\"Best Epsilon:\", best_params['epsilon'])\n",
        "\n",
        "# Create the best model using the best hyperparameters\n",
        "best_model = SVR(kernel=best_kernel, C=best_C, epsilon=best_epsilon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08315053-9eb5-44a0-b65c-c1a4760e8ca4",
      "metadata": {
        "id": "08315053-9eb5-44a0-b65c-c1a4760e8ca4"
      },
      "outputs": [],
      "source": [
        "#Test again the tuned model\n",
        "best_model.fit(x_subset_train, y_subset_train)\n",
        "y_pred = best_model.predict(x1_test)\n",
        "tuned_mse = mean_squared_error(y1_test, y_pred)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(tuned_mse)\n",
        "\n",
        "# Perform cross-validation to calculate RMSE for each fold\n",
        "neg_mse_scores = cross_val_score(best_model, x_subset_train, y_subset_train, cv=5, scoring='neg_mean_squared_error')\n",
        "rmse_scores = np.sqrt(-neg_mse_scores)\n",
        "\n",
        "# Calculate Mean RMSE and SD RMSE for cross-validation\n",
        "mean_rmse_cv = rmse_scores.mean()\n",
        "std_rmse_cv = rmse_scores.std()\n",
        "\n",
        "print(\"Tuned Model Mean Squared Error:\", tuned_mse)\n",
        "print(\"Tuned Model RMSE:\", rmse)\n",
        "print(\"Mean RMSE (CV):\", mean_rmse_cv)\n",
        "print(\"SD RMSE (CV):\",std_rmse_cv)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5Decision Tree Regression"
      ],
      "metadata": {
        "id": "KtywYKB_2QK7"
      },
      "id": "KtywYKB_2QK7"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor"
      ],
      "metadata": {
        "id": "D5YbODDr2Pyn"
      },
      "id": "D5YbODDr2Pyn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Decision Tree Regressor\n",
        "decision_tree = DecisionTreeRegressor(max_depth=5, random_state=42)"
      ],
      "metadata": {
        "id": "ODKuwkkp2mlI"
      },
      "id": "ODKuwkkp2mlI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the Decision Tree model to your training data\n",
        "decision_tree.fit(x1_train, y1_train)"
      ],
      "metadata": {
        "id": "w4uIE_up2owj"
      },
      "id": "w4uIE_up2owj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained model to make predictions on your test dataset\n",
        "y1_pred = decision_tree.predict(x1_test)"
      ],
      "metadata": {
        "id": "ujFo-Gq12oyl"
      },
      "id": "ujFo-Gq12oyl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Model\n",
        "\n",
        "mse = mean_squared_error(y1_test, y1_pred)\n",
        "r2 = decision_tree.score(x1_test, y1_test)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R-squared:\", r2)"
      ],
      "metadata": {
        "id": "6HzsF81o2o1Q"
      },
      "id": "6HzsF81o2o1Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the Decision Tree\n",
        "\n",
        "num_feature_names = ['hour_of_day', 'day_of_week', 'occupancy', 'distance']\n",
        "\n",
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plot_tree(decision_tree, feature_names=num_feature_names, filled=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E1tLle6I2o3Q"
      },
      "id": "E1tLle6I2o3Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decistion Tree Regression Fine Tuning"
      ],
      "metadata": {
        "id": "N3eX3dmO2q9l"
      },
      "id": "N3eX3dmO2q9l"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "# Create a Decision Tree Regressor\n",
        "decision_tree = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Define a grid of hyperparameters to search\n",
        "param_grid = {\n",
        "    'max_depth': [5, 10, 15, None],  # Vary the maximum depth\n",
        "    'min_samples_split': [2, 5, 10],  # Vary the minimum samples required to split a node\n",
        "    'min_samples_leaf': [1, 2, 4]  # Vary the minimum samples required at leaf nodes\n",
        "}\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(decision_tree, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# Fit the grid search to your data\n",
        "grid_search.fit(x1_train, y1_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Get the best model from the grid search\n",
        "best_decision_tree = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y1_pred = best_decision_tree.predict(x1_test)\n",
        "r2 = r2_score(y1_test, y1_pred)\n",
        "\n",
        "# Calculate the Mean Squared Error for the decision tree\n",
        "tuned_mse_decision_tree = mean_squared_error(y1_test, y1_pred)\n",
        "\n",
        "# Calculate RMSE for the decision tree\n",
        "rmse_decision_tree = np.sqrt(tuned_mse_decision_tree)\n",
        "\n",
        "# Perform cross-validation to calculate RMSE for each fold for the decision tree\n",
        "neg_mse_scores_decision_tree = cross_val_score(best_decision_tree, x_subset_train, y_subset_train, cv=5, scoring='neg_mean_squared_error')\n",
        "rmse_scores_decision_tree = np.sqrt(-neg_mse_scores_decision_tree)\n",
        "\n",
        "# Calculate Mean RMSE and SD RMSE for cross-validation for the decision tree\n",
        "mean_rmse_cv_decision_tree = rmse_scores_decision_tree.mean()\n",
        "std_rmse_cv_decision_tree = rmse_scores_decision_tree.std()\n",
        "print(\"R Square:\", r2)\n",
        "print(\"Tuned Decision Tree Mean Squared Error:\", tuned_mse_decision_tree)\n",
        "print(\"Tuned Decision Tree RMSE:\", rmse_decision_tree)\n",
        "print(\"Mean RMSE (CV) for Decision Tree:\", mean_rmse_cv_decision_tree)\n",
        "print(\"SD RMSE (CV) for Decision Tree:\", std_rmse_cv_decision_tree)"
      ],
      "metadata": {
        "id": "OG8bDHxb243j"
      },
      "id": "OG8bDHxb243j",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}